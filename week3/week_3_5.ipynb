{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0.6302521008403361\n",
      "0.6228070175438597\n",
      "0.6065573770491803\n",
      "0.6517857142857143\n",
      "3\n",
      "TP:  43  FP:  34\n",
      "FN:  59  TN:  64\n",
      "\n",
      "Accuracy:  0.535\n",
      "Precision:  0.5584415584415584\n",
      "Recall:  0.4215686274509804\n",
      "F1:  0.48044692737430167\n",
      "\n",
      "AUC-ROC logreg:  0.719187675070028\n",
      "AUC-ROC svm:  0.7086834733893557\n",
      "AUC-ROC knn:  0.6351540616246498\n",
      "AUC-ROC tree:  0.6919267707082833\n",
      "\n",
      "Logreg max:  0.6302521008403361\n",
      "SVM max:  0.6228070175438597\n",
      "KNN max:  0.6065573770491803\n",
      "Tree max:  0.6517857142857143\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "__author__ = 'nyash myash'\n",
    "\n",
    "\n",
    "import pandas\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data = pandas.read_csv(\"scores.csv\", sep=\",\", header=None)\n",
    "# print data\n",
    "\n",
    "\n",
    "y_true = data.values[1:,0].astype(np.float)\n",
    "logreg = data.values[1:,1].astype(np.float)\n",
    "svm = data.values[1:,2].astype(np.float)\n",
    "knn = data.values[1:,3].astype(np.float)\n",
    "tree = data.values[1:,4].astype(np.float)\n",
    "\n",
    "scores = np.array([logreg,svm,knn,tree])\n",
    "\n",
    "\n",
    "res = map(lambda x:roc_auc_score(y_true,x), scores)\n",
    "print res.index(max(res))\n",
    "\n",
    "max_precision = 0.0\n",
    "score_num = 0\n",
    "\n",
    "\n",
    "for num,score in enumerate(scores):\n",
    "    precision, recall, thresholds = precision_recall_curve(y_true, score)\n",
    "    prc = []\n",
    "    for i in xrange(len(recall)):\n",
    "        if recall[i] >= 0.7:\n",
    "            prc.append(precision[i])\n",
    "    print max(prc)\n",
    "    if max(prc) > max_precision:\n",
    "        max_precision = max(prc)\n",
    "        score_num = num\n",
    "\n",
    "print num\n",
    "\n",
    "# another way\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# Assignment 4 - Quality metrics\n",
    "\n",
    "# %matplotlib inline\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "\n",
    "data = pd.read_csv('classification.csv', header=0)\n",
    "classes_true = data.true\n",
    "classes_predicted = data.pred\n",
    "\n",
    "tp = 0\n",
    "fp = 0\n",
    "fn = 0\n",
    "tn = 0\n",
    "for i, class_true in enumerate(classes_true):\n",
    "    class_predicted = classes_predicted[i]\n",
    "    if class_predicted == 1 and class_true == 1:\n",
    "        tp += 1\n",
    "    elif class_predicted == 1 and class_true == 0:\n",
    "        fp += 1\n",
    "    elif class_predicted == 0 and class_true == 1:\n",
    "        fn += 1\n",
    "    else:\n",
    "        tn += 1\n",
    "\n",
    "# tp = sum(np.logical_and((y_predict == np.ones(y_predict .shape)).astype(np.int),(y_true == np.ones(y_predict .shape))).astype(np.int))\n",
    "# fp = sum(np.logical_and((y_predict == np.ones(y_predict .shape)).astype(np.int),(y_true == np.zeros(y_predict .shape))).astype(np.int))\n",
    "# tn = sum(np.logical_and((y_predict == np.zeros(y_predict .shape)).astype(np.int),(y_true == np.zeros(y_predict .shape))).astype(np.int))\n",
    "# fn = sum(np.logical_and((y_predict == np.zeros(y_predict .shape)).astype(np.int),(y_true == np.ones(y_predict .shape))).astype(np.int))\n",
    "\n",
    "print \"TP: \", tp, \" FP: \", fp\n",
    "print \"FN: \", fn, \" TN: \", tn\n",
    "\n",
    "print \"\\nAccuracy: \", metrics.accuracy_score(classes_true, classes_predicted)\n",
    "print \"Precision: \", metrics.precision_score(classes_true, classes_predicted)\n",
    "print \"Recall: \", metrics.recall_score(classes_true, classes_predicted)\n",
    "print \"F1: \", metrics.f1_score(classes_true, classes_predicted)\n",
    "\n",
    "data = pd.read_csv('scores.csv', header=0)\n",
    "classes_true = data.true\n",
    "classes_logreg = data.score_logreg\n",
    "classes_svm = data.score_svm\n",
    "classes_knn = data.score_knn\n",
    "classes_tree = data.score_tree\n",
    "print \"\\nAUC-ROC logreg: \", metrics.roc_auc_score(classes_true, classes_logreg)\n",
    "print \"AUC-ROC svm: \", metrics.roc_auc_score(classes_true, classes_svm)\n",
    "print \"AUC-ROC knn: \", metrics.roc_auc_score(classes_true, classes_knn)\n",
    "print \"AUC-ROC tree: \", metrics.roc_auc_score(classes_true, classes_tree)\n",
    "\n",
    "\n",
    "precision_logreg, recall_logreg, _ = metrics.precision_recall_curve(classes_true, classes_logreg)\n",
    "precision_svm, recall_svm, _ = metrics.precision_recall_curve(classes_true, classes_svm)\n",
    "precision_knn, recall_knn, _ = metrics.precision_recall_curve(classes_true, classes_knn)\n",
    "precision_tree, recall_tree, _ = metrics.precision_recall_curve(classes_true, classes_tree)\n",
    "\n",
    "recall_threshold = 0.7\n",
    "print \"\\nLogreg max: \", max(precision_logreg[recall_logreg > recall_threshold])\n",
    "print \"SVM max: \", max(precision_svm[recall_svm > recall_threshold])\n",
    "print \"KNN max: \", max(precision_knn[recall_knn > recall_threshold])\n",
    "print \"Tree max: \", max(precision_tree[recall_tree > recall_threshold])\n",
    "\n",
    "# Plot Precision-Recall curve\n",
    "plt.clf()\n",
    "plt.plot(recall_logreg, precision_logreg, label='Precision-Recall (logreg)')\n",
    "plt.plot(recall_svm, precision_svm, label='Precision-Recall (svm)')\n",
    "plt.plot(recall_knn, precision_knn, label='Precision-Recall (knn)')\n",
    "plt.plot(recall_tree, precision_tree, label='Precision-Recall (tree)')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.title('Precision-Recall Visualisation')\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
